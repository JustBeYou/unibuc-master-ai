{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9ef1250",
   "metadata": {},
   "source": [
    "## Ex 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b543a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e3892b43",
   "metadata": {},
   "source": [
    "## Ex 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73dcf45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from operator import itemgetter, not_\n",
    "from bisect import bisect_left\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7fc11e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "bound = 10\n",
    "m = 100\n",
    "\n",
    "rnd = lambda: np.random.uniform(-bound, bound)\n",
    "h = lambda a, x: (a <= x and x <= a + 1) or (a + 2 <= x and x <= a + 4)\n",
    "loss = lambda h, S: sum([h(x) != y for x, y in S])\n",
    "\n",
    "def test_case(S):\n",
    "    learned_a = learn_a(S)\n",
    "    h_erm = lambda x: h(learned_a, x)\n",
    "    return loss(h_erm, S)\n",
    "\n",
    "debug = False\n",
    "def debug_print(*args, **kwargs):\n",
    "    if debug: print(*args, **kwargs)\n",
    "    \n",
    "longest_interval = 5\n",
    "\n",
    "def learn_a(S):\n",
    "    \n",
    "    S.sort(key=itemgetter(0))\n",
    "    \n",
    "    Sx = list(map(itemgetter(0), S))\n",
    "    Sy = list(map(itemgetter(1), S))\n",
    "    \n",
    "    x_min, x_max = min(Sx), max(Sx)\n",
    "    \n",
    "    if all(Sy):\n",
    "        debug_print(f\"All positive case. a = {x_min}\")\n",
    "        return x_min\n",
    "    \n",
    "    if all(map(not_, Sy)):\n",
    "        debug_print(f\"All negative case. a = {x_max + 1}\")\n",
    "        return x_max + 1\n",
    "        \n",
    "    a_best, loss_best = np.inf, np.inf\n",
    "    \n",
    "    a_curr = x_min - 6 - 1\n",
    "    iteration = 0\n",
    "    \n",
    "    h_curr = lambda x: h(a_curr, x)\n",
    "    loss_curr = loss(h_curr, S)\n",
    "    \n",
    "    will_change_i = 0\n",
    "    old_classification = h_curr(Sx[will_change_i]) == Sy[will_change_i]\n",
    "    \n",
    "    while a_curr <= x_max:\n",
    "\n",
    "        h_curr = lambda x: h(a_curr, x)\n",
    "        new_classification = h_curr(Sx[will_change_i]) == Sy[will_change_i]\n",
    "        \n",
    "        if old_classification and new_classification:\n",
    "            pass\n",
    "        elif old_classification:\n",
    "            loss_curr += 1\n",
    "        elif new_classification:\n",
    "            loss_curr -= 1\n",
    "            \n",
    "        debug_print(f\"iteration {iteration}: a = {a_curr} loss = {loss_curr}\")\n",
    "            \n",
    "#         correct_loss = loss(h_curr, S)\n",
    "#         assert loss_curr == correct_loss\n",
    "        \n",
    "        if loss_curr < loss_best:\n",
    "            loss_best = loss_curr\n",
    "            a_best = a_curr\n",
    "            \n",
    "            debug_print(f\"new best: a = {a_curr} loss = {loss_curr}\")\n",
    "        \n",
    "        margins = [a_curr, a_curr + 1, a_curr + 2, a_curr + 4]\n",
    "        margin_dist_min = np.inf\n",
    "        will_change_i = np.inf\n",
    "        \n",
    "        for margin in margins:\n",
    "            i = bisect_left(Sx, margin)\n",
    "            if i >= len(Sx) or Sx[i] < margin: continue\n",
    "            \n",
    "            if Sx[i] - margin < margin_dist_min:\n",
    "                will_change_i = i\n",
    "                margin_dist_min = Sx[i] - margin\n",
    "                    \n",
    "        assert margin_dist_min >= 0 and margin_dist_min != np.inf and will_change_i != np.inf\n",
    "        \n",
    "        old_classification = h_curr(Sx[will_change_i]) == Sy[will_change_i]\n",
    "        a_curr += margin_dist_min + 1e-6\n",
    "        \n",
    "        iteration += 1\n",
    "    \n",
    "    debug_print(f\"solution: a = {a_best} loss = {loss_best}\")\n",
    "    \n",
    "    return a_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "076a97c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3243281841278076"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Trivial test cases\n",
    "# All true\n",
    "assert test_case([(1, True), (2, True), (4, True)]) == 0\n",
    "# All false\n",
    "assert test_case([(5, False), (6, False)]) == 0\n",
    "# All in first\n",
    "assert test_case([(1, True), (1.5, True), (2.1, False)]) == 0\n",
    "# All in second\n",
    "assert test_case([(1.9, False), (2, True), (3.5, True), (4.01, False)]) == 0\n",
    "\n",
    "# Random test case\n",
    "n = 100\n",
    "start_time = time()\n",
    "for i in range(n):\n",
    "#     print(f\"Random test case {i+1}/{n}\")\n",
    "    \n",
    "    true_a = rnd() / 2\n",
    "    f = lambda x: h(true_a, x)\n",
    "\n",
    "    Sx = [rnd() for _ in range(m)]\n",
    "    S = [(x, f(x) if np.random.random() < 0.8 else not f(x)) for x in Sx]\n",
    "\n",
    "    assert any([y for x, y in S])\n",
    "    assert any([not y for x, y in S])\n",
    "\n",
    "    test_case_loss = test_case(S)\n",
    "#     print(test_case_loss, loss(f, S))\n",
    "    assert np.isclose(test_case_loss, loss(f, S)) or test_case_loss < loss(f, S)\n",
    "    \n",
    "time() - start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24fbe1c",
   "metadata": {},
   "source": [
    "## Ex 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9cc78c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "import numpy as np\n",
    "\n",
    "def generate_nfs(n, k):\n",
    "    clauses = list(product([-1, 0, +1], repeat=n))\n",
    "    nfs = list(product(clauses, repeat=k))\n",
    "    \n",
    "    return nfs\n",
    "    \n",
    "def dnf(x, form):\n",
    "    for clause in form:\n",
    "        conj_result = True\n",
    "        for i, literal in enumerate(clause):\n",
    "            if literal == 0: \n",
    "                continue\n",
    "            \n",
    "            conj_result = conj_result and (x[i] if literal > 0 else not x[i])\n",
    "        \n",
    "        if conj_result:\n",
    "            return True\n",
    "        \n",
    "        \n",
    "    return False\n",
    "    \n",
    "def generate_x(n):\n",
    "    return [bool(np.random.binomial(1, 0.5)) for _ in range(n)]\n",
    "\n",
    "def compute_error(S, h, true_nf):\n",
    "    return sum([h(x) != dnf(x, true_nf) for x in S]) / len(S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bfc79557",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'true_nf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 26\u001b[0m\n\u001b[1;32m     22\u001b[0m             best_h_type \u001b[38;5;241m=\u001b[39m (i, j)\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m best_error, best_h_type, best_h\n\u001b[0;32m---> 26\u001b[0m learn_h(S, \u001b[43mtrue_nf\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'true_nf' is not defined"
     ]
    }
   ],
   "source": [
    "def weak_h(x, i, j):\n",
    "    x_i = x[i - 1] if i > 0 else not x[-i - 1]\n",
    "    x_j = x[j - 1] if j > 0 else not x[-j - 1]\n",
    "    return x_i or x_j\n",
    "\n",
    "def learn_h(S, true_nf):\n",
    "    best_h = lambda x: 0\n",
    "    best_h_type = None\n",
    "    best_error = compute_error(S, best_h, true_nf) \n",
    "\n",
    "    literals = list(range(-N, 0)) + list(range(1, N + 1))\n",
    "    for i, j in product(literals, repeat=2):\n",
    "        if i == -j: continue\n",
    "\n",
    "        h_curr = lambda x: weak_h(x, i, j)\n",
    "\n",
    "        error_curr = compute_error(S, h_curr, true_nf)\n",
    "\n",
    "        if error_curr < best_error and error_curr < 0.5:\n",
    "            best_error = error_curr\n",
    "            best_h = h_curr\n",
    "            best_h_type = (i, j)\n",
    "            \n",
    "    return best_error, best_h_type, best_h\n",
    "        \n",
    "learn_h(S, true_nf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "424cd2a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n",
      "warning!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.62,\n",
       "  0.4716666666666667,\n",
       "  0.23333333333333334,\n",
       "  0.23333333333333334,\n",
       "  0.13833333333333334],\n",
       " [0.23333333333333334,\n",
       "  0.23333333333333334,\n",
       "  0.22166666666666668,\n",
       "  0.13833333333333334,\n",
       "  0.115])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 3\n",
    "K = 2\n",
    "M = 6\n",
    "RETRIES = 2\n",
    "\n",
    "constant_h = lambda x: 0\n",
    "\n",
    "vals = []\n",
    "constant_vals = []\n",
    "\n",
    "nfs = generate_nfs(N, K)\n",
    "\n",
    "for true_nf in nfs:\n",
    "    for _ in range(RETRIES):\n",
    "        S = [generate_x(N) for i in range(M)]\n",
    "        best_error, best_h_type, best_h = learn_h(S, true_nf)\n",
    "#         print(best_error, best_h_type)\n",
    "        \n",
    "        large_S = [generate_x(N) for i in range(100*M)]\n",
    "        e = compute_error(large_S, best_h, true_nf)\n",
    "        constant_e = compute_error(large_S, constant_h, true_nf)\n",
    "        \n",
    "        if constant_e < e:\n",
    "            print(\"warning!\")\n",
    "        \n",
    "        vals.append(e)\n",
    "        constant_vals.append(constant_e)\n",
    "        \n",
    "        \n",
    "sorted(vals[:5], reverse=True), sorted(constant_vals[:5], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0f817fc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error rate of weak learner: 0.40616\n",
      "Baseline error rate: 0.5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def weak_learn(S, y):\n",
    "    d = S.shape[1]\n",
    "    best_i, best_j, best_error = None, None, float('inf')\n",
    "    # Iterate over all pairs of literals\n",
    "    for i in range(d):\n",
    "        for j in range(i+1, d):\n",
    "            # Construct a hypothesis\n",
    "            h = np.logical_or(S[:, i], S[:, j])\n",
    "            error = np.mean(h != y)\n",
    "            # Update best literals if error is lower\n",
    "            if error < best_error:\n",
    "                best_i, best_j, best_error = i, j, error\n",
    "\n",
    "    # Error of the constant classifier\n",
    "    constant_error = min(np.mean(y), 1 - np.mean(y))\n",
    "\n",
    "    if best_error < constant_error:\n",
    "        # If best pair of literals has smaller error than the constant classifier\n",
    "        return np.logical_or(S[:, best_i], S[:, best_j])\n",
    "    else:\n",
    "        # Otherwise, return the majority class\n",
    "        majority_class = np.argmax(np.bincount(y))\n",
    "        return np.full(S.shape[0], majority_class)\n",
    "\n",
    "\n",
    "def f(random_array):\n",
    "    return (random_array[:, 0] & random_array[:, 2] & random_array[:, 4]) | (random_array[:, 1] & (~random_array[:, 2]) & random_array[:, 5])\n",
    "    \n",
    "# Function to generate a random dataset\n",
    "def generate_dataset(n, d):\n",
    "    S = np.random.randint(2, size=(n, d))\n",
    "    y = f(S)\n",
    "    return S, y\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "# np.random.seed(42)\n",
    "\n",
    "# Initialize error counters\n",
    "learner_error = 0\n",
    "baseline_error = 0\n",
    "\n",
    "# Number of trials\n",
    "trials = 1000\n",
    "\n",
    "# Test the weak learner over many random datasets\n",
    "for _ in range(trials):\n",
    "    # Generate a random dataset\n",
    "    S, y = generate_dataset(100, 10)\n",
    "    \n",
    "    # Get the hypothesis from the weak learner\n",
    "    h = weak_learn(S, y)\n",
    "    \n",
    "    # Compute the error rate of the weak learner\n",
    "    learner_error += np.mean(h != y)\n",
    "    \n",
    "    # Compute the baseline error rate (assuming random guessing)\n",
    "    baseline_error += 0.5\n",
    "\n",
    "# Average the error rates\n",
    "learner_error /= trials\n",
    "baseline_error /= trials\n",
    "\n",
    "print(f'Error rate of weak learner: {learner_error}')\n",
    "print(f'Baseline error rate: {baseline_error}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a7f99016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Umm?\n",
      "[[1 1 1 1 1 1 0]\n",
      " [0 0 0 1 1 0 1]\n",
      " [1 0 0 1 1 1 1]\n",
      " [1 0 1 0 1 1 1]\n",
      " [0 1 0 1 1 0 0]]\n",
      "Umm?\n",
      "[[1 1 1 1 1 1 1]\n",
      " [0 1 0 1 0 0 0]\n",
      " [1 1 0 0 0 0 1]\n",
      " [1 1 1 1 1 0 1]\n",
      " [0 0 1 0 0 1 1]]\n",
      "Umm?\n",
      "[[1 1 1 0 1 0 1]\n",
      " [1 0 1 0 0 1 1]\n",
      " [0 0 1 1 0 0 1]\n",
      " [0 1 1 1 0 0 0]\n",
      " [1 1 1 1 1 0 0]]\n",
      "Umm?\n",
      "[[1 1 1 1 0 0 1]\n",
      " [1 0 1 0 1 1 1]\n",
      " [1 0 1 1 1 1 1]\n",
      " [0 0 0 1 1 0 1]\n",
      " [0 1 1 0 1 0 1]]\n",
      "Umm?\n",
      "[[1 1 0 1 1 1 1]\n",
      " [0 0 0 1 1 1 0]\n",
      " [0 1 1 0 0 1 1]\n",
      " [1 1 1 1 1 1 0]\n",
      " [0 1 0 0 0 1 1]]\n",
      "Umm?\n",
      "[[1 0 1 0 1 1 1]\n",
      " [0 1 0 1 1 0 0]\n",
      " [0 0 0 1 0 1 1]\n",
      " [1 0 0 0 1 1 1]\n",
      " [1 1 0 1 0 1 1]]\n",
      "Umm?\n",
      "[[0 0 0 1 1 0 0]\n",
      " [0 1 0 1 1 0 0]\n",
      " [1 1 1 1 1 0 1]\n",
      " [1 1 1 0 1 1 1]\n",
      " [1 0 1 1 0 0 1]]\n",
      "Umm?\n",
      "[[0 1 1 1 0 0 1]\n",
      " [0 1 0 1 0 1 1]\n",
      " [0 1 0 1 1 1 1]\n",
      " [0 0 1 1 0 0 0]\n",
      " [0 0 1 0 0 1 0]]\n",
      "Umm?\n",
      "[[1 1 0 1 0 0 1]\n",
      " [1 1 1 0 1 0 0]\n",
      " [1 0 1 0 1 1 0]\n",
      " [0 1 1 0 1 1 1]\n",
      " [0 0 0 1 1 0 1]]\n",
      "Umm?\n",
      "[[1 1 1 1 0 1 0]\n",
      " [1 0 1 1 1 1 0]\n",
      " [1 1 1 1 1 0 0]\n",
      " [1 1 1 1 0 1 0]\n",
      " [0 1 0 1 1 0 1]]\n",
      "Umm?\n",
      "[[0 1 0 1 1 0 0]\n",
      " [0 1 0 0 1 1 0]\n",
      " [1 1 1 0 0 0 1]\n",
      " [0 1 0 0 0 1 0]\n",
      " [1 0 1 1 1 1 0]]\n",
      "Umm?\n",
      "[[0 1 0 1 1 1 1]\n",
      " [0 1 0 0 1 0 1]\n",
      " [0 1 1 1 1 1 0]\n",
      " [1 0 1 0 1 0 0]\n",
      " [0 0 1 0 1 1 1]]\n",
      "Umm?\n",
      "[[1 1 0 1 0 1 1]\n",
      " [0 1 0 1 0 1 0]\n",
      " [0 0 1 0 1 0 0]\n",
      " [0 0 1 0 0 0 0]\n",
      " [1 0 1 1 0 1 1]]\n",
      "Umm?\n",
      "[[0 0 1 0 1 1 1]\n",
      " [0 0 0 0 0 1 1]\n",
      " [0 1 0 0 1 1 0]\n",
      " [0 1 1 0 1 0 0]\n",
      " [1 0 1 1 1 1 1]]\n",
      "Umm?\n",
      "[[1 0 1 1 1 1 1]\n",
      " [1 1 0 0 1 1 0]\n",
      " [0 1 0 1 1 0 1]\n",
      " [1 0 1 1 0 0 1]\n",
      " [1 0 0 0 1 0 1]]\n",
      "Umm?\n",
      "[[0 1 0 1 1 0 1]\n",
      " [1 1 0 1 1 1 1]\n",
      " [1 1 0 1 0 1 1]\n",
      " [0 0 1 0 0 1 1]\n",
      " [1 0 1 0 1 1 1]]\n",
      "Umm?\n",
      "[[1 0 1 0 1 0 0]\n",
      " [0 1 0 1 0 1 0]\n",
      " [0 1 1 1 0 1 1]\n",
      " [1 0 1 0 1 1 1]\n",
      " [1 0 0 0 1 1 1]]\n",
      "Umm?\n",
      "[[1 0 1 0 1 1 0]\n",
      " [0 0 1 0 0 0 0]\n",
      " [0 0 0 1 1 1 1]\n",
      " [1 1 1 1 1 1 0]\n",
      " [1 0 0 1 1 1 0]]\n",
      "Umm?\n",
      "[[0 1 1 1 1 0 0]\n",
      " [1 1 0 1 1 1 0]\n",
      " [1 1 1 1 0 1 0]\n",
      " [1 0 1 0 1 1 0]\n",
      " [1 0 0 0 1 0 0]]\n",
      "Umm?\n",
      "[[0 1 0 0 1 1 1]\n",
      " [0 0 0 0 1 0 0]\n",
      " [1 1 1 1 0 0 1]\n",
      " [1 1 0 1 0 1 1]\n",
      " [1 0 1 1 1 0 0]]\n",
      "Umm?\n",
      "[[1 0 1 1 0 1 1]\n",
      " [1 0 1 0 1 1 0]\n",
      " [1 0 1 1 1 1 0]\n",
      " [0 1 0 1 1 1 0]\n",
      " [1 0 0 1 1 1 0]]\n",
      "Umm?\n",
      "[[1 0 1 0 1 0 0]\n",
      " [0 1 1 1 0 1 1]\n",
      " [0 0 1 0 0 0 0]\n",
      " [1 1 0 0 0 1 0]\n",
      " [1 0 0 0 1 1 0]]\n",
      "Umm?\n",
      "[[1 1 1 0 1 1 0]\n",
      " [1 1 1 1 1 0 0]\n",
      " [1 1 0 0 0 1 0]\n",
      " [1 0 1 1 0 1 0]\n",
      " [0 0 0 1 1 0 1]]\n",
      "Umm?\n",
      "[[0 0 1 1 0 1 0]\n",
      " [1 0 1 1 1 0 1]\n",
      " [0 1 1 0 0 1 1]\n",
      " [1 1 0 0 0 1 1]\n",
      " [1 0 1 1 0 1 1]]\n",
      "Umm?\n",
      "[[1 1 1 0 1 1 1]\n",
      " [0 1 0 1 0 0 1]\n",
      " [1 1 0 0 0 0 0]\n",
      " [0 0 1 0 1 1 1]\n",
      " [1 1 1 1 1 1 1]]\n",
      "Umm?\n",
      "[[0 1 1 0 1 0 1]\n",
      " [1 0 1 1 1 1 1]\n",
      " [1 1 0 0 1 1 0]\n",
      " [0 0 1 0 1 1 1]\n",
      " [0 1 0 0 0 1 1]]\n",
      "Umm?\n",
      "[[0 0 1 1 1 1 0]\n",
      " [1 1 0 0 0 0 0]\n",
      " [1 1 0 0 0 1 0]\n",
      " [0 1 0 0 0 1 0]\n",
      " [0 0 0 1 1 1 1]]\n",
      "Umm?\n",
      "[[1 0 1 1 0 1 1]\n",
      " [1 0 0 0 1 1 1]\n",
      " [1 1 0 1 0 1 0]\n",
      " [1 1 1 0 1 1 0]\n",
      " [1 0 1 0 1 1 1]]\n",
      "Umm?\n",
      "[[0 0 1 1 1 0 0]\n",
      " [1 1 0 0 0 1 0]\n",
      " [1 0 0 0 0 1 1]\n",
      " [0 0 0 1 0 0 0]\n",
      " [0 1 0 0 0 1 0]]\n",
      "Umm?\n",
      "[[0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 1 0]\n",
      " [1 0 1 0 1 0 1]\n",
      " [1 1 0 1 1 1 1]\n",
      " [0 1 1 1 0 1 1]]\n",
      "Umm?\n",
      "[[0 0 0 0 1 0 0]\n",
      " [0 1 0 1 1 1 0]\n",
      " [1 0 0 0 1 1 1]\n",
      " [1 1 1 0 1 0 1]\n",
      " [0 1 1 1 1 1 0]]\n",
      "Umm?\n",
      "[[1 0 0 1 1 0 0]\n",
      " [1 0 1 0 1 1 1]\n",
      " [1 1 0 1 0 1 1]\n",
      " [1 0 0 1 1 1 0]\n",
      " [0 1 1 0 0 1 0]]\n",
      "Umm?\n",
      "[[1 1 0 0 1 0 0]\n",
      " [1 0 1 0 1 0 1]\n",
      " [0 0 1 1 0 1 1]\n",
      " [1 0 1 1 1 1 1]\n",
      " [0 1 0 1 0 1 1]]\n",
      "Umm?\n",
      "[[1 0 1 0 0 1 0]\n",
      " [1 0 1 0 1 0 0]\n",
      " [0 1 1 0 1 1 0]\n",
      " [1 0 1 0 0 0 0]\n",
      " [1 1 0 1 0 1 1]]\n",
      "Umm?\n",
      "[[0 1 0 0 1 1 1]\n",
      " [0 0 1 1 0 1 1]\n",
      " [1 1 0 0 0 1 1]\n",
      " [1 0 0 1 0 0 0]\n",
      " [0 1 1 1 1 1 1]]\n",
      "Umm?\n",
      "[[1 1 1 0 0 1 0]\n",
      " [0 0 0 1 1 1 1]\n",
      " [0 0 1 1 1 0 1]\n",
      " [1 0 1 1 1 1 0]\n",
      " [1 1 1 1 1 1 0]]\n",
      "Umm?\n",
      "[[0 1 0 1 1 1 0]\n",
      " [1 0 1 1 0 0 1]\n",
      " [1 1 0 1 1 0 0]\n",
      " [0 1 0 1 0 0 0]\n",
      " [1 1 1 0 1 1 0]]\n",
      "Umm?\n",
      "[[1 1 0 1 1 1 0]\n",
      " [1 0 1 0 0 0 0]\n",
      " [1 0 0 1 0 0 0]\n",
      " [0 1 1 1 0 1 1]\n",
      " [0 1 0 1 0 1 1]]\n",
      "Umm?\n",
      "[[1 1 1 0 1 0 1]\n",
      " [1 1 0 0 1 0 1]\n",
      " [0 0 1 1 0 1 0]\n",
      " [1 1 1 1 1 0 0]\n",
      " [0 0 1 0 0 0 0]]\n",
      "Umm?\n",
      "[[0 1 1 0 1 0 0]\n",
      " [1 1 0 1 1 1 0]\n",
      " [0 0 1 1 1 0 0]\n",
      " [1 0 0 0 0 1 1]\n",
      " [1 1 1 0 1 0 1]]\n",
      "Umm?\n",
      "[[0 0 0 1 0 1 1]\n",
      " [0 1 0 1 0 1 1]\n",
      " [1 1 0 0 1 0 0]\n",
      " [0 1 0 0 1 1 0]\n",
      " [0 0 0 0 1 1 0]]\n",
      "Umm?\n",
      "[[1 0 1 0 1 0 0]\n",
      " [1 1 0 1 1 1 0]\n",
      " [0 1 1 1 0 1 0]\n",
      " [1 0 0 0 1 0 1]\n",
      " [1 0 0 0 0 0 1]]\n",
      "Umm?\n",
      "[[1 1 1 0 1 0 1]\n",
      " [0 0 1 1 1 1 0]\n",
      " [0 0 1 1 1 1 1]\n",
      " [0 1 0 0 1 0 0]\n",
      " [1 1 0 0 0 1 1]]\n",
      "Umm?\n",
      "[[0 1 1 0 1 0 0]\n",
      " [0 1 0 1 0 1 1]\n",
      " [1 0 0 1 1 0 1]\n",
      " [0 1 0 1 1 1 0]\n",
      " [1 0 0 1 1 1 1]]\n",
      "Umm?\n",
      "[[1 0 0 0 0 0 0]\n",
      " [0 1 1 0 0 1 0]\n",
      " [1 1 1 0 1 1 0]\n",
      " [0 0 0 1 0 1 1]\n",
      " [1 1 0 1 0 1 1]]\n",
      "Umm?\n",
      "[[1 0 1 1 0 0 1]\n",
      " [0 1 0 0 0 0 1]\n",
      " [1 0 1 1 1 1 0]\n",
      " [0 0 1 1 1 0 1]\n",
      " [1 1 1 0 1 1 1]]\n",
      "Umm?\n",
      "[[0 1 1 1 0 1 1]\n",
      " [0 0 0 1 0 1 1]\n",
      " [1 0 1 0 1 0 0]\n",
      " [1 0 0 0 1 1 1]\n",
      " [1 0 1 1 1 1 1]]\n",
      "Umm?\n",
      "[[1 1 1 0 1 0 1]\n",
      " [0 0 1 0 1 1 0]\n",
      " [1 0 0 1 1 1 1]\n",
      " [1 0 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 0]]\n",
      "Umm?\n",
      "[[1 1 0 0 1 1 1]\n",
      " [1 0 1 0 0 0 0]\n",
      " [0 1 0 1 1 1 0]\n",
      " [1 1 1 0 1 0 0]\n",
      " [0 1 1 1 1 1 0]]\n",
      "Umm?\n",
      "[[0 1 1 0 1 1 0]\n",
      " [0 1 1 0 0 0 1]\n",
      " [0 0 0 1 1 1 0]\n",
      " [1 0 1 0 1 0 1]\n",
      " [1 1 0 1 1 1 1]]\n",
      "Umm?\n",
      "[[0 1 0 1 1 1 0]\n",
      " [0 0 0 0 1 0 0]\n",
      " [0 1 0 1 1 1 0]\n",
      " [0 1 1 1 0 1 0]\n",
      " [0 0 1 0 0 1 1]]\n",
      "Umm?\n",
      "[[1 0 1 1 0 1 1]\n",
      " [0 1 0 0 1 1 1]\n",
      " [1 1 1 0 0 1 1]\n",
      " [0 1 0 0 0 1 1]\n",
      " [1 1 1 1 1 0 1]]\n",
      "Umm?\n",
      "[[0 1 0 1 0 0 0]\n",
      " [1 1 0 1 0 1 0]\n",
      " [1 0 0 1 1 1 1]\n",
      " [0 1 0 0 0 1 1]\n",
      " [0 1 0 1 1 0 1]]\n",
      "Umm?\n",
      "[[0 0 1 0 1 1 0]\n",
      " [1 0 1 0 1 1 0]\n",
      " [0 1 1 1 1 0 0]\n",
      " [0 1 0 0 1 1 1]\n",
      " [0 0 0 1 0 1 1]]\n",
      "Umm?\n",
      "[[0 0 1 1 1 0 1]\n",
      " [0 1 0 0 1 1 1]\n",
      " [1 0 0 0 0 1 1]\n",
      " [0 0 0 1 1 1 1]\n",
      " [1 1 1 1 1 0 1]]\n",
      "Umm?\n",
      "[[0 1 0 0 1 1 0]\n",
      " [1 0 1 1 0 0 1]\n",
      " [0 0 1 1 0 1 1]\n",
      " [1 1 0 1 1 1 1]\n",
      " [0 1 1 1 1 1 1]]\n",
      "Umm?\n",
      "[[1 1 1 1 1 0 1]\n",
      " [1 0 1 0 1 0 1]\n",
      " [0 1 1 0 1 0 1]\n",
      " [0 1 0 0 0 0 0]\n",
      " [1 1 0 0 0 0 0]]\n",
      "Umm?\n",
      "[[1 1 0 0 0 1 1]\n",
      " [1 1 1 0 1 0 1]\n",
      " [1 0 1 0 1 1 0]\n",
      " [0 0 1 1 1 1 0]\n",
      " [1 0 1 0 0 0 0]]\n",
      "Umm?\n",
      "[[0 1 0 1 0 1 0]\n",
      " [1 0 1 0 1 0 0]\n",
      " [0 0 0 1 0 0 0]\n",
      " [1 1 1 1 0 1 1]\n",
      " [0 0 1 0 0 0 0]]\n",
      "Umm?\n",
      "[[0 1 0 1 0 0 1]\n",
      " [1 0 1 1 1 0 1]\n",
      " [0 1 0 1 0 1 0]\n",
      " [0 1 1 0 0 0 1]\n",
      " [1 0 0 1 1 0 1]]\n",
      "Umm?\n",
      "[[1 0 1 1 0 0 1]\n",
      " [1 1 0 1 1 1 1]\n",
      " [1 1 0 1 0 1 0]\n",
      " [0 1 0 1 0 0 0]\n",
      " [0 1 1 1 1 1 1]]\n",
      "Umm?\n",
      "[[1 1 1 1 0 1 1]\n",
      " [1 0 1 1 0 0 0]\n",
      " [1 1 0 1 0 1 0]\n",
      " [1 1 0 1 0 0 1]\n",
      " [1 0 1 1 1 0 1]]\n",
      "Umm?\n",
      "[[0 0 1 1 1 0 1]\n",
      " [1 0 1 1 1 0 1]\n",
      " [1 1 1 0 1 0 0]\n",
      " [0 1 1 0 0 0 0]\n",
      " [0 0 0 1 1 1 0]]\n",
      "Umm?\n",
      "[[0 1 1 1 1 1 1]\n",
      " [1 0 1 1 1 1 1]\n",
      " [0 0 0 0 1 0 0]\n",
      " [1 1 1 0 1 1 1]\n",
      " [0 1 0 1 1 1 1]]\n",
      "Umm?\n",
      "[[1 0 1 0 1 0 1]\n",
      " [0 1 1 0 1 0 0]\n",
      " [0 1 1 1 0 0 1]\n",
      " [0 0 0 1 0 1 0]\n",
      " [1 1 1 0 1 0 0]]\n",
      "Umm?\n",
      "[[0 1 0 0 0 1 0]\n",
      " [1 1 0 0 0 1 1]\n",
      " [1 0 1 1 0 1 1]\n",
      " [0 1 1 1 1 0 0]\n",
      " [0 1 0 0 0 0 1]]\n",
      "Umm?\n",
      "[[1 0 1 0 0 0 1]\n",
      " [1 1 0 0 0 1 0]\n",
      " [1 1 1 1 1 0 1]\n",
      " [0 0 1 0 1 0 0]\n",
      " [1 0 0 1 1 1 0]]\n",
      "Umm?\n",
      "[[0 1 1 0 1 0 1]\n",
      " [1 0 0 1 1 1 0]\n",
      " [1 1 1 1 1 0 0]\n",
      " [0 0 1 0 0 1 0]\n",
      " [0 1 0 1 0 1 1]]\n",
      "Umm?\n",
      "[[1 1 0 0 1 1 0]\n",
      " [1 0 1 1 0 1 0]\n",
      " [0 1 1 1 0 0 1]\n",
      " [0 1 0 0 0 0 0]\n",
      " [1 1 0 0 0 1 1]]\n",
      "Umm?\n",
      "[[1 1 1 1 0 1 1]\n",
      " [1 0 1 1 1 1 0]\n",
      " [0 0 1 1 0 0 0]\n",
      " [1 1 0 1 0 1 0]\n",
      " [0 0 0 0 0 0 0]]\n",
      "Umm?\n",
      "[[1 0 1 0 1 0 1]\n",
      " [0 1 1 0 0 1 0]\n",
      " [0 1 0 1 1 1 1]\n",
      " [0 0 1 1 1 1 1]\n",
      " [0 0 0 0 0 1 1]]\n",
      "Umm?\n",
      "[[1 1 1 1 0 1 0]\n",
      " [1 1 0 1 0 1 0]\n",
      " [0 1 1 1 0 0 1]\n",
      " [0 0 1 0 0 1 0]\n",
      " [1 1 1 0 1 0 1]]\n",
      "Umm?\n",
      "[[1 0 0 1 0 1 0]\n",
      " [0 1 0 1 1 1 0]\n",
      " [1 1 0 1 0 1 0]\n",
      " [1 0 0 1 1 0 1]\n",
      " [1 1 0 0 1 0 1]]\n",
      "Umm?\n",
      "[[1 0 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 0]\n",
      " [1 0 1 0 1 0 1]\n",
      " [1 0 0 1 1 1 0]\n",
      " [1 0 1 0 0 0 0]]\n",
      "Umm?\n",
      "[[0 0 1 0 0 0 1]\n",
      " [1 1 0 0 1 1 0]\n",
      " [0 1 1 1 1 1 0]\n",
      " [1 1 0 1 1 1 1]\n",
      " [1 1 0 0 1 1 1]]\n",
      "Umm?\n",
      "[[1 1 0 1 1 0 1]\n",
      " [0 1 0 0 0 1 1]\n",
      " [0 0 1 0 1 1 1]\n",
      " [1 1 0 0 0 1 1]\n",
      " [0 0 0 0 0 0 0]]\n",
      "Umm?\n",
      "[[1 1 1 0 1 1 1]\n",
      " [1 1 0 1 1 1 0]\n",
      " [0 0 1 0 1 0 1]\n",
      " [1 0 0 0 0 1 0]\n",
      " [1 1 1 0 0 1 0]]\n",
      "Umm?\n",
      "[[0 0 0 0 0 0 1]\n",
      " [1 0 0 0 0 0 1]\n",
      " [0 1 1 0 1 0 1]\n",
      " [1 0 1 0 1 1 1]\n",
      " [1 0 1 0 1 0 1]]\n",
      "Umm?\n",
      "[[1 1 1 1 1 0 0]\n",
      " [1 0 0 1 1 0 0]\n",
      " [1 1 0 1 0 1 0]\n",
      " [0 1 1 0 0 0 0]\n",
      " [0 1 1 0 0 0 1]]\n",
      "Umm?\n",
      "[[1 1 0 1 1 1 0]\n",
      " [1 0 1 1 1 1 0]\n",
      " [1 1 1 1 1 1 1]\n",
      " [1 1 0 1 1 0 1]\n",
      " [0 0 0 1 0 1 1]]\n",
      "Umm?\n",
      "[[1 1 0 1 1 0 0]\n",
      " [0 0 1 0 0 0 1]\n",
      " [0 0 0 1 1 0 0]\n",
      " [0 1 0 1 1 1 0]\n",
      " [1 1 1 0 1 1 1]]\n",
      "Umm?\n",
      "[[1 0 1 0 1 0 0]\n",
      " [0 0 0 0 0 0 1]\n",
      " [0 0 0 1 0 0 1]\n",
      " [1 1 1 0 0 1 1]\n",
      " [1 1 0 0 0 1 1]]\n",
      "Umm?\n",
      "[[1 1 0 1 1 0 0]\n",
      " [0 1 1 0 1 1 0]\n",
      " [1 0 1 0 1 0 1]\n",
      " [0 0 0 1 1 0 0]\n",
      " [1 1 1 0 1 0 1]]\n",
      "Umm?\n",
      "[[0 0 1 1 1 1 0]\n",
      " [1 0 0 1 1 1 1]\n",
      " [0 0 1 0 1 0 0]\n",
      " [0 1 0 1 1 1 1]\n",
      " [1 1 0 0 1 1 0]]\n",
      "Umm?\n",
      "[[0 1 0 1 1 1 0]\n",
      " [0 0 1 1 0 0 1]\n",
      " [0 0 1 0 1 1 0]\n",
      " [1 0 0 1 1 1 0]\n",
      " [1 0 1 0 1 0 1]]\n",
      "Umm?\n",
      "[[0 1 0 1 1 0 1]\n",
      " [0 1 1 0 0 1 1]\n",
      " [1 0 1 0 1 0 1]\n",
      " [0 0 1 0 1 1 1]\n",
      " [0 1 0 1 1 1 1]]\n",
      "Umm?\n",
      "[[0 0 1 1 1 1 1]\n",
      " [1 0 1 1 1 1 1]\n",
      " [1 0 1 0 1 0 0]\n",
      " [1 0 1 1 1 0 1]\n",
      " [1 0 1 1 0 0 1]]\n",
      "Umm?\n",
      "[[0 0 1 1 1 0 1]\n",
      " [1 1 0 0 1 1 1]\n",
      " [1 1 0 0 1 1 0]\n",
      " [0 1 0 1 1 0 0]\n",
      " [0 0 0 1 0 1 0]]\n",
      "Umm?\n",
      "[[0 1 0 1 0 1 1]\n",
      " [0 1 1 1 0 1 0]\n",
      " [0 0 1 0 1 0 1]\n",
      " [1 0 0 0 0 1 0]\n",
      " [1 0 1 1 1 1 0]]\n",
      "Umm?\n",
      "[[1 0 1 0 0 0 0]\n",
      " [1 1 0 1 0 1 0]\n",
      " [1 1 0 1 1 0 1]\n",
      " [1 1 1 0 1 1 1]\n",
      " [0 0 1 0 0 1 0]]\n",
      "Umm?\n",
      "[[1 0 1 1 1 0 1]\n",
      " [1 1 1 1 1 1 0]\n",
      " [0 0 0 1 0 0 1]\n",
      " [0 1 0 1 0 1 0]\n",
      " [1 1 1 1 0 1 1]]\n",
      "Umm?\n",
      "[[1 1 0 0 0 1 0]\n",
      " [1 1 1 1 1 0 0]\n",
      " [1 0 1 1 0 1 1]\n",
      " [1 1 0 0 0 0 0]\n",
      " [0 0 1 0 0 1 0]]\n",
      "Umm?\n",
      "[[0 1 1 0 0 0 0]\n",
      " [1 1 0 0 1 1 0]\n",
      " [1 0 1 1 1 0 0]\n",
      " [0 1 1 0 0 0 1]\n",
      " [1 0 1 1 0 1 0]]\n",
      "Umm?\n",
      "[[0 0 1 1 0 0 0]\n",
      " [1 1 1 1 1 0 0]\n",
      " [1 1 0 1 0 0 1]\n",
      " [1 0 0 0 1 1 1]\n",
      " [0 1 0 0 0 1 0]]\n",
      "Umm?\n",
      "[[1 1 1 1 0 1 1]\n",
      " [1 1 1 1 1 1 1]\n",
      " [1 1 0 1 1 0 1]\n",
      " [1 0 1 0 1 1 1]\n",
      " [0 1 0 1 0 0 0]]\n",
      "Umm?\n",
      "[[1 1 1 1 1 1 0]\n",
      " [1 1 0 1 1 1 1]\n",
      " [1 0 0 1 1 1 1]\n",
      " [1 1 0 0 1 0 0]\n",
      " [1 0 1 1 1 1 0]]\n",
      "Umm?\n",
      "[[1 1 0 1 1 0 1]\n",
      " [0 1 0 0 1 0 0]\n",
      " [1 1 1 0 0 1 1]\n",
      " [1 1 1 0 1 1 1]\n",
      " [1 0 1 0 1 0 0]]\n",
      "Umm?\n",
      "[[0 0 1 1 1 0 1]\n",
      " [0 0 0 1 0 1 1]\n",
      " [1 1 1 0 1 0 0]\n",
      " [1 0 0 0 1 1 1]\n",
      " [1 1 0 1 0 1 0]]\n",
      "Umm?\n",
      "[[1 1 1 0 0 1 0]\n",
      " [1 0 0 1 1 1 0]\n",
      " [1 0 0 1 0 1 1]\n",
      " [1 0 1 1 1 0 1]\n",
      " [1 0 1 1 1 1 0]]\n",
      "Umm?\n",
      "[[0 1 0 0 0 1 0]\n",
      " [0 1 1 1 1 0 0]\n",
      " [1 0 1 0 0 0 0]\n",
      " [0 1 0 1 1 1 0]\n",
      " [0 0 1 1 0 1 0]]\n",
      "Umm?\n",
      "[[1 0 1 0 1 0 1]\n",
      " [0 0 0 0 1 0 0]\n",
      " [1 1 1 0 1 1 0]\n",
      " [1 0 1 1 0 1 0]\n",
      " [0 1 1 1 1 1 1]]\n",
      "Umm?\n",
      "[[1 0 1 0 0 1 0]\n",
      " [1 1 1 1 1 0 1]\n",
      " [1 1 0 0 1 0 1]\n",
      " [1 1 0 0 1 1 1]\n",
      " [0 0 1 0 0 0 1]]\n",
      "Umm?\n",
      "[[0 1 0 1 0 0 1]\n",
      " [1 1 1 0 0 0 0]\n",
      " [1 0 0 1 1 1 1]\n",
      " [1 1 0 0 1 1 0]\n",
      " [1 0 1 1 1 0 1]]\n",
      "Umm?\n",
      "[[0 0 0 0 0 1 0]\n",
      " [0 1 0 1 0 0 1]\n",
      " [1 1 1 0 1 1 1]\n",
      " [1 1 1 1 1 0 1]\n",
      " [1 1 1 0 0 1 0]]\n",
      "Umm?\n",
      "[[0 1 1 1 0 1 0]\n",
      " [0 0 1 1 1 0 0]\n",
      " [1 0 1 1 1 0 1]\n",
      " [0 1 0 0 0 0 0]\n",
      " [0 1 0 1 0 1 0]]\n",
      "Umm?\n",
      "[[1 1 1 1 1 1 0]\n",
      " [0 0 1 1 1 1 0]\n",
      " [0 1 0 1 1 0 1]\n",
      " [0 1 0 1 1 1 1]\n",
      " [0 1 0 0 1 1 0]]\n",
      "Umm?\n",
      "[[0 1 0 1 1 0 1]\n",
      " [1 0 0 0 1 0 1]\n",
      " [0 0 0 0 0 1 0]\n",
      " [0 1 0 1 1 1 1]\n",
      " [1 0 1 1 1 1 0]]\n",
      "Umm?\n",
      "[[0 1 1 1 1 0 0]\n",
      " [0 0 1 1 1 1 0]\n",
      " [0 1 0 1 0 1 0]\n",
      " [0 0 1 0 1 1 0]\n",
      " [1 1 1 1 1 0 1]]\n",
      "Umm?\n",
      "[[0 1 0 1 1 1 1]\n",
      " [0 1 0 1 1 1 1]\n",
      " [1 1 1 0 0 0 1]\n",
      " [1 0 0 1 1 0 1]\n",
      " [1 1 1 1 1 0 1]]\n",
      "Umm?\n",
      "[[0 1 1 1 1 1 0]\n",
      " [1 0 1 0 1 0 0]\n",
      " [0 0 1 1 1 1 0]\n",
      " [1 1 1 0 1 1 0]\n",
      " [1 0 0 0 0 1 1]]\n",
      "Umm?\n",
      "[[1 1 0 0 0 1 1]\n",
      " [0 0 1 0 1 0 1]\n",
      " [0 1 0 1 1 1 0]\n",
      " [1 1 1 1 0 0 0]\n",
      " [0 0 1 0 1 1 1]]\n",
      "Umm?\n",
      "[[0 1 1 1 0 1 0]\n",
      " [0 1 1 0 0 1 0]\n",
      " [1 0 1 1 0 0 1]\n",
      " [0 1 0 1 1 1 1]\n",
      " [1 1 0 1 0 1 1]]\n",
      "Umm?\n",
      "[[1 0 0 0 0 1 1]\n",
      " [1 1 1 0 0 1 1]\n",
      " [1 0 1 0 1 1 0]\n",
      " [1 0 0 0 1 0 1]\n",
      " [0 1 0 0 1 1 0]]\n",
      "Umm?\n",
      "[[0 1 0 0 1 1 1]\n",
      " [1 1 1 1 1 1 1]\n",
      " [1 0 1 1 0 0 0]\n",
      " [0 0 0 1 1 0 1]\n",
      " [1 0 1 1 1 0 1]]\n",
      "Umm?\n",
      "[[1 1 0 1 1 1 0]\n",
      " [1 0 1 0 1 0 1]\n",
      " [0 1 1 0 1 1 0]\n",
      " [0 0 0 0 1 1 0]\n",
      " [0 1 1 1 1 1 1]]\n",
      "Umm?\n",
      "[[1 1 1 0 1 1 1]\n",
      " [1 0 1 0 1 0 0]\n",
      " [1 0 0 1 1 1 1]\n",
      " [1 1 0 0 0 1 0]\n",
      " [0 1 0 1 1 0 1]]\n",
      "Umm?\n",
      "[[1 0 1 0 1 0 1]\n",
      " [1 0 0 1 0 1 1]\n",
      " [0 1 0 0 1 1 1]\n",
      " [0 1 0 0 1 0 0]\n",
      " [1 1 0 0 1 1 1]]\n",
      "Umm?\n",
      "[[0 1 0 0 1 1 0]\n",
      " [1 0 1 1 1 1 1]\n",
      " [0 1 1 0 1 1 0]\n",
      " [1 0 0 1 1 0 0]\n",
      " [0 1 0 1 1 1 1]]\n",
      "Umm?\n",
      "[[0 0 0 1 1 1 1]\n",
      " [0 1 0 0 0 1 1]\n",
      " [1 0 1 0 1 1 0]\n",
      " [1 0 0 0 0 0 1]\n",
      " [0 0 1 1 1 0 1]]\n",
      "Umm?\n",
      "[[1 1 1 1 0 0 0]\n",
      " [1 0 1 0 0 1 0]\n",
      " [1 1 0 0 1 0 0]\n",
      " [1 1 1 0 1 1 0]\n",
      " [1 1 0 1 1 1 0]]\n",
      "Umm?\n",
      "[[0 1 1 0 1 0 0]\n",
      " [1 0 1 0 1 1 1]\n",
      " [1 1 0 0 1 1 0]\n",
      " [1 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 1 0]]\n",
      "Umm?\n",
      "[[1 1 1 0 1 0 1]\n",
      " [0 1 0 0 0 1 0]\n",
      " [0 1 0 0 0 1 0]\n",
      " [0 1 0 0 1 0 1]\n",
      " [0 0 1 0 1 1 0]]\n",
      "Umm?\n",
      "[[0 0 0 1 1 1 0]\n",
      " [0 1 1 1 0 1 0]\n",
      " [1 0 1 1 1 0 1]\n",
      " [1 1 1 1 1 1 0]\n",
      " [1 0 0 0 0 1 0]]\n",
      "Umm?\n",
      "[[1 1 0 1 1 1 1]\n",
      " [1 0 0 0 1 0 1]\n",
      " [1 1 1 1 0 1 1]\n",
      " [0 1 1 0 1 0 1]\n",
      " [0 1 0 1 1 1 0]]\n",
      "Umm?\n",
      "[[1 1 1 1 0 1 0]\n",
      " [1 0 1 1 1 1 1]\n",
      " [0 0 1 1 0 1 1]\n",
      " [0 1 0 0 0 1 1]\n",
      " [0 1 0 0 1 1 1]]\n",
      "Umm?\n",
      "[[1 1 0 1 0 0 1]\n",
      " [0 0 1 1 0 1 0]\n",
      " [0 0 0 1 1 1 1]\n",
      " [1 0 1 1 1 1 1]\n",
      " [1 1 0 1 1 1 0]]\n",
      "Umm?\n",
      "[[1 0 0 0 0 0 1]\n",
      " [0 1 1 1 0 1 1]\n",
      " [1 0 1 0 1 1 0]\n",
      " [1 1 1 0 0 0 0]\n",
      " [1 0 1 0 1 0 1]]\n",
      "Umm?\n",
      "[[1 0 1 1 1 0 1]\n",
      " [1 0 0 1 1 0 1]\n",
      " [1 1 0 1 0 0 0]\n",
      " [1 0 1 0 0 0 1]\n",
      " [1 1 1 1 1 0 1]]\n",
      "Umm?\n",
      "[[0 0 0 0 1 1 1]\n",
      " [1 1 0 1 0 0 0]\n",
      " [1 1 1 0 1 1 0]\n",
      " [1 1 1 0 1 1 1]\n",
      " [0 0 0 1 0 0 0]]\n",
      "Umm?\n",
      "[[0 0 0 1 1 0 0]\n",
      " [1 0 1 0 1 0 1]\n",
      " [1 1 0 0 0 0 0]\n",
      " [0 0 1 1 1 0 1]\n",
      " [0 1 0 0 1 1 1]]\n",
      "Umm?\n",
      "[[1 0 1 0 0 0 1]\n",
      " [1 1 1 1 1 1 1]\n",
      " [0 0 0 0 1 0 0]\n",
      " [0 1 0 1 0 1 1]\n",
      " [0 1 1 0 0 1 1]]\n",
      "Umm?\n",
      "[[1 1 0 0 0 0 1]\n",
      " [0 1 1 1 1 0 1]\n",
      " [1 1 1 1 1 1 0]\n",
      " [1 1 1 1 1 0 1]\n",
      " [0 0 0 1 1 0 1]]\n",
      "Umm?\n",
      "[[0 1 1 1 0 0 1]\n",
      " [1 1 1 0 1 1 1]\n",
      " [0 0 0 1 0 0 0]\n",
      " [1 1 1 1 0 1 1]\n",
      " [1 1 1 0 1 1 0]]\n",
      "Umm?\n",
      "[[1 1 0 0 0 0 0]\n",
      " [1 1 0 1 0 1 1]\n",
      " [1 1 1 0 1 1 1]\n",
      " [1 0 1 0 1 1 0]\n",
      " [1 1 1 1 0 1 1]]\n",
      "Umm?\n",
      "[[0 1 0 1 0 0 1]\n",
      " [0 1 1 0 0 1 1]\n",
      " [1 0 0 1 0 1 1]\n",
      " [1 1 1 0 1 1 1]\n",
      " [1 0 1 1 1 1 1]]\n",
      "Umm?\n",
      "[[1 1 1 1 1 1 1]\n",
      " [1 1 0 1 1 1 1]\n",
      " [1 0 1 0 1 1 0]\n",
      " [1 1 1 1 0 0 1]\n",
      " [1 1 0 1 1 0 1]]\n",
      "Umm?\n",
      "[[0 1 1 0 0 0 1]\n",
      " [1 1 0 0 1 1 1]\n",
      " [1 0 0 1 1 0 1]\n",
      " [1 1 1 1 1 0 1]\n",
      " [0 1 0 1 0 0 0]]\n",
      "Umm?\n",
      "[[0 1 0 0 0 1 0]\n",
      " [1 0 1 1 1 0 0]\n",
      " [0 0 0 1 0 1 1]\n",
      " [0 1 0 1 0 1 0]\n",
      " [1 1 0 1 1 0 0]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Umm?\n",
      "[[1 1 0 0 1 1 0]\n",
      " [1 0 0 0 1 1 1]\n",
      " [1 1 1 1 0 1 0]\n",
      " [1 1 1 0 0 1 0]\n",
      " [1 0 1 0 1 0 1]]\n",
      "Umm?\n",
      "[[1 1 1 1 1 0 0]\n",
      " [1 0 0 1 0 1 1]\n",
      " [1 0 0 1 1 0 1]\n",
      " [1 0 1 1 0 0 0]\n",
      " [1 1 1 1 1 0 1]]\n",
      "Umm?\n",
      "[[1 0 1 0 0 0 1]\n",
      " [0 1 0 1 0 1 0]\n",
      " [1 0 0 1 1 1 1]\n",
      " [1 1 1 0 0 1 1]\n",
      " [1 1 1 1 1 0 0]]\n",
      "Umm?\n",
      "[[1 1 1 0 0 1 1]\n",
      " [0 1 1 0 0 1 1]\n",
      " [0 1 0 1 0 1 0]\n",
      " [1 1 1 0 1 0 1]\n",
      " [0 1 0 0 1 0 0]]\n",
      "Umm?\n",
      "[[0 1 0 0 0 0 1]\n",
      " [1 1 1 0 0 1 0]\n",
      " [1 1 1 1 1 1 0]\n",
      " [0 1 0 1 1 1 0]\n",
      " [0 1 1 1 0 1 0]]\n",
      "Umm?\n",
      "[[1 0 0 1 0 0 1]\n",
      " [0 0 1 1 0 1 0]\n",
      " [1 1 0 1 0 1 0]\n",
      " [0 1 1 0 0 1 1]\n",
      " [1 1 0 1 0 1 0]]\n",
      "Umm?\n",
      "[[0 0 1 0 1 1 1]\n",
      " [1 1 1 1 1 1 0]\n",
      " [0 0 1 0 1 1 1]\n",
      " [0 1 0 0 0 1 1]\n",
      " [0 1 1 0 1 1 0]]\n",
      "Umm?\n",
      "[[1 1 0 1 1 0 1]\n",
      " [1 1 1 0 1 0 1]\n",
      " [0 0 0 1 1 0 1]\n",
      " [0 0 1 1 1 1 1]\n",
      " [1 1 1 1 1 0 1]]\n",
      "Umm?\n",
      "[[1 1 1 0 1 1 1]\n",
      " [1 0 1 0 0 1 1]\n",
      " [0 1 0 1 0 1 0]\n",
      " [0 0 0 0 0 1 0]\n",
      " [0 1 0 0 1 0 0]]\n",
      "Umm?\n",
      "[[1 1 1 0 0 1 1]\n",
      " [0 1 0 1 0 0 1]\n",
      " [1 1 1 1 1 1 0]\n",
      " [0 1 0 0 0 1 1]\n",
      " [1 0 1 0 1 1 1]]\n",
      "Umm?\n",
      "[[1 0 1 0 1 0 0]\n",
      " [0 0 0 0 0 0 1]\n",
      " [1 1 0 1 0 1 1]\n",
      " [1 0 0 1 1 1 1]\n",
      " [1 1 1 1 0 0 1]]\n",
      "Umm?\n",
      "[[0 0 1 0 0 1 0]\n",
      " [0 1 0 1 0 0 1]\n",
      " [0 1 0 1 1 1 0]\n",
      " [1 0 1 0 1 1 1]\n",
      " [0 1 1 1 1 0 1]]\n",
      "Umm?\n",
      "[[0 1 0 1 1 1 0]\n",
      " [1 1 1 1 0 1 1]\n",
      " [1 0 0 0 1 0 1]\n",
      " [1 1 1 1 1 0 0]\n",
      " [1 0 0 0 1 1 0]]\n",
      "Umm?\n",
      "[[1 1 1 1 0 1 0]\n",
      " [1 1 1 0 0 0 0]\n",
      " [0 0 0 1 1 0 0]\n",
      " [1 1 1 0 1 1 0]\n",
      " [1 0 1 1 1 1 1]]\n",
      "Umm?\n",
      "[[1 0 1 1 1 0 1]\n",
      " [0 0 1 0 1 1 1]\n",
      " [1 0 1 0 1 0 1]\n",
      " [0 0 1 0 0 0 1]\n",
      " [0 1 1 1 1 0 1]]\n",
      "Umm?\n",
      "[[0 0 1 0 1 1 0]\n",
      " [1 0 0 1 1 1 0]\n",
      " [1 1 0 0 1 1 0]\n",
      " [1 0 1 1 1 0 0]\n",
      " [0 0 0 0 0 1 1]]\n",
      "Umm?\n",
      "[[0 1 1 1 1 0 0]\n",
      " [0 1 0 0 1 1 1]\n",
      " [1 0 1 0 0 1 0]\n",
      " [1 0 1 0 1 1 1]\n",
      " [1 0 0 1 1 0 0]]\n",
      "Umm?\n",
      "[[1 1 1 1 1 0 1]\n",
      " [0 1 0 1 0 0 1]\n",
      " [0 0 1 0 0 0 1]\n",
      " [1 1 1 1 1 0 0]\n",
      " [1 0 0 1 1 0 0]]\n",
      "Umm?\n",
      "[[1 0 1 0 1 0 1]\n",
      " [1 1 1 0 0 1 1]\n",
      " [1 1 1 0 1 1 0]\n",
      " [1 0 1 1 1 1 0]\n",
      " [1 0 0 1 1 0 1]]\n",
      "Umm?\n",
      "[[1 1 1 0 1 1 1]\n",
      " [0 0 1 1 0 1 1]\n",
      " [0 1 1 0 0 1 0]\n",
      " [1 0 1 1 0 1 1]\n",
      " [1 1 0 1 1 1 1]]\n",
      "Umm?\n",
      "[[0 1 0 0 1 1 1]\n",
      " [1 1 0 0 0 1 1]\n",
      " [1 0 1 1 1 1 1]\n",
      " [1 0 1 0 0 0 0]\n",
      " [0 0 0 1 1 1 1]]\n",
      "Umm?\n",
      "[[1 0 1 0 0 1 0]\n",
      " [0 1 0 1 0 1 0]\n",
      " [0 1 1 1 1 0 0]\n",
      " [1 1 0 0 0 1 0]\n",
      " [1 1 1 0 1 0 0]]\n",
      "Umm?\n",
      "[[1 0 0 1 0 0 0]\n",
      " [0 1 0 1 1 1 1]\n",
      " [1 1 0 1 1 1 1]\n",
      " [0 0 0 1 1 0 1]\n",
      " [1 1 1 0 0 0 1]]\n",
      "Umm?\n",
      "[[1 0 0 0 0 1 1]\n",
      " [0 1 1 0 0 1 1]\n",
      " [1 1 0 0 0 1 1]\n",
      " [0 0 1 0 0 1 1]\n",
      " [1 0 1 1 1 1 1]]\n",
      "Umm?\n",
      "[[0 1 0 0 0 1 0]\n",
      " [1 0 1 1 0 0 1]\n",
      " [1 1 1 0 1 0 0]\n",
      " [0 0 1 0 0 1 1]\n",
      " [1 1 0 1 1 0 1]]\n",
      "Umm?\n",
      "[[1 0 0 1 1 0 1]\n",
      " [1 1 0 0 0 1 1]\n",
      " [0 0 0 1 1 0 0]\n",
      " [1 0 1 0 1 1 1]\n",
      " [0 0 1 1 0 1 0]]\n",
      "Umm?\n",
      "[[0 0 0 1 0 1 1]\n",
      " [1 1 0 0 1 0 0]\n",
      " [1 0 1 0 1 1 0]\n",
      " [1 1 0 0 1 1 0]\n",
      " [0 0 1 1 1 1 0]]\n",
      "Umm?\n",
      "[[0 0 1 1 1 0 0]\n",
      " [1 1 1 1 1 1 1]\n",
      " [1 1 0 1 1 1 1]\n",
      " [0 0 0 1 1 1 1]\n",
      " [1 0 0 0 1 0 1]]\n",
      "Umm?\n",
      "[[1 1 1 1 1 1 1]\n",
      " [1 1 0 1 0 0 0]\n",
      " [1 1 0 1 1 1 0]\n",
      " [0 1 1 1 1 0 1]\n",
      " [0 1 1 1 0 0 1]]\n",
      "Umm?\n",
      "[[1 0 1 1 1 0 1]\n",
      " [1 1 1 0 1 0 1]\n",
      " [0 1 1 1 0 0 1]\n",
      " [0 1 0 1 0 1 1]\n",
      " [0 0 0 0 1 1 1]]\n",
      "Umm?\n",
      "[[1 1 0 0 1 1 1]\n",
      " [1 0 1 1 0 1 1]\n",
      " [0 1 0 1 0 0 1]\n",
      " [1 0 1 1 1 0 1]\n",
      " [1 0 1 0 0 0 0]]\n",
      "Umm?\n",
      "[[1 1 0 1 0 1 1]\n",
      " [0 1 1 1 0 1 0]\n",
      " [0 1 0 0 1 1 0]\n",
      " [0 1 0 1 0 1 0]\n",
      " [1 1 1 1 0 1 1]]\n",
      "Umm?\n",
      "[[1 1 0 1 0 1 1]\n",
      " [0 1 1 1 0 1 0]\n",
      " [0 1 0 0 1 1 0]\n",
      " [0 1 0 1 0 1 0]\n",
      " [1 1 1 1 0 1 1]]\n",
      "Umm?\n",
      "[[1 1 1 1 1 0 1]\n",
      " [1 1 1 0 1 0 1]\n",
      " [0 0 0 0 0 0 1]\n",
      " [1 0 1 0 0 0 0]\n",
      " [1 1 1 1 0 1 0]]\n",
      "Umm?\n",
      "[[0 1 1 0 1 1 1]\n",
      " [1 1 0 0 0 1 1]\n",
      " [0 0 0 0 0 1 0]\n",
      " [0 0 0 1 0 0 1]\n",
      " [1 0 1 1 1 0 1]]\n",
      "Umm?\n",
      "[[1 1 1 0 1 1 0]\n",
      " [1 0 0 1 1 0 1]\n",
      " [1 1 1 1 1 0 1]\n",
      " [0 1 1 0 0 0 1]\n",
      " [0 0 0 1 0 0 1]]\n",
      "Umm?\n",
      "[[1 0 1 1 1 1 1]\n",
      " [1 1 0 1 1 0 1]\n",
      " [0 0 1 1 0 1 0]\n",
      " [0 0 1 0 1 0 0]\n",
      " [0 1 0 0 1 1 1]]\n",
      "Umm?\n",
      "[[1 1 1 1 0 1 0]\n",
      " [1 0 0 1 1 1 0]\n",
      " [1 1 0 1 0 1 1]\n",
      " [1 0 1 1 1 1 0]\n",
      " [1 1 1 0 0 1 0]]\n",
      "Umm?\n",
      "[[1 1 0 1 0 1 1]\n",
      " [1 1 0 0 1 1 1]\n",
      " [0 1 0 0 0 1 1]\n",
      " [1 0 1 1 1 1 0]\n",
      " [0 1 1 1 1 1 1]]\n",
      "Umm?\n",
      "[[1 1 0 0 1 1 0]\n",
      " [0 1 0 1 1 1 1]\n",
      " [1 1 0 1 1 1 0]\n",
      " [1 1 0 0 0 1 1]\n",
      " [1 1 1 0 0 1 1]]\n",
      "Umm?\n",
      "[[0 1 0 1 1 1 1]\n",
      " [1 1 1 0 1 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [1 0 1 1 0 1 1]\n",
      " [0 1 0 0 1 0 1]]\n",
      "Umm?\n",
      "[[0 0 0 1 1 1 0]\n",
      " [0 0 1 0 1 0 1]\n",
      " [0 1 0 1 1 1 0]\n",
      " [1 0 0 1 1 1 1]\n",
      " [1 1 1 0 1 0 0]]\n",
      "Umm?\n",
      "[[0 1 0 0 1 1 0]\n",
      " [1 0 0 1 1 0 1]\n",
      " [1 1 1 0 1 1 0]\n",
      " [0 1 1 1 0 0 1]\n",
      " [1 0 1 1 0 0 0]]\n",
      "Umm?\n",
      "[[1 1 1 1 0 1 0]\n",
      " [0 0 0 0 0 0 1]\n",
      " [1 1 1 1 1 1 1]\n",
      " [0 0 1 1 1 1 0]\n",
      " [1 1 0 1 1 1 0]]\n",
      "Umm?\n",
      "[[0 1 1 0 1 1 0]\n",
      " [1 0 1 1 1 1 0]\n",
      " [1 0 1 1 0 0 0]\n",
      " [1 0 1 0 1 0 1]\n",
      " [0 1 1 0 0 0 1]]\n",
      "Umm?\n",
      "[[0 1 0 1 1 1 0]\n",
      " [1 0 1 0 0 1 1]\n",
      " [1 1 1 0 1 1 0]\n",
      " [0 0 0 1 1 0 1]\n",
      " [1 0 0 1 0 1 1]]\n",
      "Umm?\n",
      "[[0 1 0 1 0 1 1]\n",
      " [0 1 0 0 1 1 0]\n",
      " [0 0 0 0 1 1 1]\n",
      " [1 0 1 1 0 0 1]\n",
      " [0 1 0 1 1 1 1]]\n",
      "Umm?\n",
      "[[1 1 0 1 1 1 1]\n",
      " [1 0 1 0 1 0 1]\n",
      " [1 0 0 1 0 0 0]\n",
      " [0 1 1 1 1 1 1]\n",
      " [1 0 0 1 0 0 1]]\n",
      "Umm?\n",
      "[[1 1 1 1 1 1 1]\n",
      " [0 1 0 1 1 1 0]\n",
      " [1 1 1 1 0 1 0]\n",
      " [1 0 1 0 1 1 0]\n",
      " [1 1 0 1 1 0 0]]\n",
      "Umm?\n",
      "[[0 1 0 1 1 0 1]\n",
      " [1 1 1 1 1 1 0]\n",
      " [0 1 0 1 0 1 1]\n",
      " [0 1 0 0 1 1 1]\n",
      " [1 0 1 0 0 0 1]]\n",
      "Umm?\n",
      "[[0 0 0 1 1 1 1]\n",
      " [1 1 1 1 1 0 0]\n",
      " [0 0 0 0 0 1 1]\n",
      " [1 0 1 0 1 1 0]\n",
      " [0 1 1 0 1 0 0]]\n",
      "Umm?\n",
      "[[0 1 0 1 0 1 1]\n",
      " [0 0 0 1 1 1 0]\n",
      " [1 1 0 1 1 1 1]\n",
      " [1 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 1]]\n",
      "Umm?\n",
      "[[0 1 0 1 1 1 0]\n",
      " [0 0 1 1 1 1 0]\n",
      " [1 1 0 1 1 0 0]\n",
      " [1 1 1 0 1 0 0]\n",
      " [1 0 1 1 1 0 0]]\n",
      "Umm?\n",
      "[[0 1 0 0 1 0 0]\n",
      " [0 1 0 1 0 1 0]\n",
      " [1 1 0 0 1 0 1]\n",
      " [1 1 1 0 1 0 0]\n",
      " [0 1 1 0 1 0 0]]\n",
      "Umm?\n",
      "[[1 1 0 0 1 0 0]\n",
      " [1 1 0 0 1 1 0]\n",
      " [1 1 1 1 1 0 0]\n",
      " [0 0 0 0 1 1 1]\n",
      " [1 1 1 0 0 0 1]]\n",
      "Umm?\n",
      "[[1 0 0 0 1 0 0]\n",
      " [0 1 0 0 1 1 1]\n",
      " [0 1 1 0 0 1 1]\n",
      " [1 1 0 1 0 1 1]\n",
      " [0 0 0 1 1 0 0]]\n",
      "Error rate of weak learner: 591\n",
      "Baseline error rate: 1143\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pprint\n",
    "\n",
    "def weak_learn(S, y):\n",
    "    d = S.shape[1]\n",
    "    best_i, best_j, best_error = None, None, float('inf')\n",
    "    # Iterate over all pairs of literals\n",
    "    for i in range(d):\n",
    "        for j in range(i+1, d):\n",
    "            # Construct a hypothesis\n",
    "            h = np.logical_or(S[:, i], S[:, j])\n",
    "            error = np.mean(h != y)\n",
    "            # Update best literals if error is lower\n",
    "            if error < best_error:\n",
    "                best_i, best_j, best_error = i, j, error\n",
    "\n",
    "    # Error of the constant classifier\n",
    "    constant_error = min(np.mean(y), 1 - np.mean(y))\n",
    "\n",
    "    if best_error < constant_error:\n",
    "        # If best pair of literals has smaller error than the constant classifier\n",
    "        return np.logical_or(S[:, best_i], S[:, best_j])\n",
    "    else:\n",
    "        # Otherwise, return the majority class\n",
    "        majority_class = np.argmax(np.bincount(y))\n",
    "        return np.full(S.shape[0], majority_class)\n",
    "\n",
    "def f(random_array):\n",
    "    return (random_array[:, 0] & random_array[:, 2] & random_array[:, 4]) | (random_array[:, 1] & (~random_array[:, 2]) & random_array[:, 5])\n",
    "    \n",
    "# Function to generate a random dataset\n",
    "def generate_dataset(n, d):\n",
    "    S = np.random.randint(2, size=(n, d))\n",
    "    y = f(S)\n",
    "    return S, y\n",
    "\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "# np.random.seed(42)\n",
    "\n",
    "# Initialize error counters\n",
    "learner_error = 0\n",
    "baseline_error = 0\n",
    "\n",
    "# Number of trials\n",
    "trials = 1000\n",
    "\n",
    "# Positive class ratio\n",
    "pos_ratio = 0.50\n",
    "\n",
    "# Test the weak learner over many random imbalanced datasets\n",
    "for _ in range(trials):\n",
    "    # Generate a random imbalanced dataset\n",
    "    S, y = generate_dataset(5, 7)\n",
    "    \n",
    "    # Get the hypothesis from the weak learner\n",
    "    h = weak_learn(S, y)\n",
    "    \n",
    "    # Compute the error rate of the weak learner\n",
    "    for a, b in zip(h, y):\n",
    "        if a != b and not b:\n",
    "            print(\"Umm?\")\n",
    "            print(S)\n",
    "            \n",
    "        \n",
    "    learner_error += np.sum(h != y)\n",
    "    \n",
    "    # Compute the baseline error rate (assuming random guessing)\n",
    "    baseline_error += min(np.sum(y), len(y) - np.sum(y))\n",
    "\n",
    "# Average the error rates\n",
    "# learner_error /= trials\n",
    "# baseline_error /= trials\n",
    "\n",
    "print(f'Error rate of weak learner: {learner_error}')\n",
    "print(f'Baseline error rate: {baseline_error}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
